{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "ed34f904-cf40-48f5-b90a-b083d4043f5f",
    "cellId": "5ldw55plglsb7weiafepeg"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import io\n",
    "from os import path\n",
    "from glob import iglob\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import lightgbm as lgb\n",
    "import h5py\n",
    "import boto3\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"cntk\"\n",
    "os.environ['AWS_DEFAULT_REGION'] = \"ru-central1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "a1a82e7f-fbf4-40a2-9a86-8173e59a51a4",
    "cellId": "434q7sj6roqwdqifx3ja7",
    "execution_id": "b80a5d27-b40e-442d-9c33-86fef8c432c9"
   },
   "source": [
    "## Connect to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "n8tzeurbz0chafewnwhx0h"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "# Name of your bucket with images\n",
    "bucket_name = 'bucketwithvideo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "669b3f25-f610-4aac-b7df-248d30d6b251",
    "cellId": "ylws7qzms1zr15n1rotw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "session = boto3.session.Session()\n",
    "\n",
    "ENDPOINT = \"https://storage.yandexcloud.net\"\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id = (os.environ['token']),\n",
    "    aws_secret_access_key = (os.environ['key_value']),\n",
    "    region_name = (os.environ['AWS_DEFAULT_REGION']),\n",
    ")\n",
    "\n",
    "\n",
    "s3 = session.client(\n",
    "    \"s3\", endpoint_url=ENDPOINT)\n",
    "\n",
    "# Get list of bucket objects\n",
    "fail_files = s3.list_objects_v2(Bucket=bucket_name, Prefix ='bus/bus', MaxKeys  = 1000)['Contents']\n",
    "pass_files = s3.list_objects_v2(Bucket=bucket_name, Prefix ='car/car', MaxKeys  = 1000)['Contents']\n",
    "\n",
    "df_fail_files = pd.DataFrame(fail_files)\n",
    "df_pass_files =  pd.DataFrame(pass_files)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "a4ddce5d-26de-4f32-bfeb-1ae513f6db6f",
    "cellId": "utzkk30m4ooys3ghdmqqk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def from_s3(bucket, key):\n",
    "    file_byte_string = s3.get_object(Bucket=bucket, Key=key)['Body'].read()\n",
    "    img = Image.open(io.BytesIO(file_byte_string))\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "14edc7cc-8857-4ccc-8698-760086e567f3",
    "cellId": "zwzkfpi53e12gf2e37lrvi",
    "execution_id": "4d97ee0a-13cb-4d1a-bbaf-5d087a28a6f1"
   },
   "source": [
    "## Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "ab937779-d932-4260-86e7-62bf8fa1683c",
    "cellId": "50i7pauhqckmo791y4gzf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "image_paths = sorted(df_fail_files.Key.values) + sorted(df_pass_files.Key.values)\n",
    "total_files = len(fail_files) + len(pass_files)\n",
    "labels = np.zeros(total_files)\n",
    "labels[len(fail_files):] = 1\n",
    "print(labels)\n",
    "print ('Number of fail images {0} pass images {1} total {2};'.format(len(fail_files),len(pass_files), len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "2c9abfcb-6139-487a-85d6-2b5c8ed896ab",
    "cellId": "2mtjl29t7rb7ekavbviz0d"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "pil_image = from_s3(bucket_name, image_paths[950])\n",
    "print(pil_image.size)\n",
    "pil_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "ff23b7e4-98c1-48bd-b363-9185f852dc72",
    "cellId": "su3o7g2ds2995p4pr0oib",
    "execution_id": "ce4ceb08-c568-47ed-868e-64b11eeec3e3"
   },
   "source": [
    "## Calculating the characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "fbdd5c86-e60f-4fc9-b390-5cfd9cf83fa0",
    "cellId": "b2wbmxg73enn52lsnmy1d"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model = ResNet50(weights='imagenet',  input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "d779b3bb-5c07-4fdd-8615-ca1665b7956e",
    "cellId": "us7l74u2m9aocnjclynngf"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def file_batch(file_list, batch_size):\n",
    "    for i in range(0, len(file_list), batch_size):\n",
    "        yield file_list[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "e98aa630-42cc-458b-991c-8f3b61a5dc9c",
    "cellId": "02hesofdanh29wdqapecrwo"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def featurize_images(file_list, model, batch_size=32):\n",
    "    features = []\n",
    "    \n",
    "    for fb in tqdm(file_batch(file_list, batch_size)):\n",
    "        load_img = []\n",
    "        for file_path in fb:\n",
    "            print(file_path)\n",
    "            img = from_s3(bucket_name,file_path).resize((224, 224))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            load_img.append(preprocess_input(x))\n",
    "            arr_pred = model.predict_on_batch(np.concatenate(load_img))\n",
    "            print('arr_pred.shape {0} arr_pred.squeeze.shape: {1}'.format(arr_pred.shape,np.squeeze(arr_pred).shape))\n",
    "        features.extend(arr_pred.squeeze())\n",
    "    return np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "14f016e2-b416-4c55-a11c-396554c3d164",
    "cellId": "0a09df4ua15vqkkeq91jub9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "# Execution of this cell will takes 10-15 minutes\n",
    "%%time\n",
    "\n",
    "\n",
    "features_filename = \"../features_resnet50.npy\"\n",
    "if path.isfile(features_filename):\n",
    "    print(\"Features found!\")\n",
    "    features = np.load(features_filename)\n",
    "else:\n",
    "    print(\"Computing features\")\n",
    "    features = featurize_images(image_paths, model) \n",
    "    np.save(features_filename, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "6731082b-0755-4225-802a-4dc88c45f8cb",
    "cellId": "b3vg56x2wmfgsksfmp4mc4"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "# Check the size of array\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "5bff6d8a-d6d5-4b10-8d4a-266e3d372b99",
    "cellId": "1m035lwdxsedxdrs9sgjgd",
    "execution_id": "5bbee806-9ece-4ce4-a22c-040e4610bf98"
   },
   "source": [
    "## Training and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "83b027f5-7a38-4a9e-8164-3947db1b939d",
    "cellId": "ljieqbps732feqpigydl9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=2048, shuffle=True)\n",
    "cv_results = pd.DataFrame(columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC', 'Confusion Matrix'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "b5e5bf1a-3b70-49ca-8b89-7e4984c1fc9b",
    "cellId": "vs8ra49c24dafrs8gmdg5",
    "execution_id": "42eb312b-b251-4e2b-8f4e-3ab2e25bf2a4"
   },
   "source": [
    "The function `classification_metrics` is used to calculate quality metrics for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "c6cd2e64-1cdf-41ef-8d29-8c5cca7d3562",
    "cellId": "nzl4qca1h6lqbwq99el0km"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "def classification_metrics(y_true, y_pred_proba, threshold=0.5):\n",
    "    y_pred = np.where(y_pred_proba > threshold, 1, 0)\n",
    "    cm_dict = {}\n",
    "    cm_dict['Accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    cm_dict['Precision'] =  precision_score(y_true, y_pred)\n",
    "    cm_dict['Recall'] =  recall_score(y_true, y_pred)\n",
    "    cm_dict['F1'] =  f1_score(y_true, y_pred) \n",
    "    cm_dict['AUC'] = roc_auc_score(y_true, y_pred_proba)\n",
    "    cm_dict['Confusion Matrix'] = confusion_matrix(y_true, y_pred).tolist()\n",
    "    return cm_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "a3d5eb48-23c4-4dfb-bf86-db5bc1bbef00",
    "cellId": "mmr0a5kngn82oe9ifi4xp1",
    "execution_id": "07c0150e-5af5-47ec-8042-96af4e00dbff"
   },
   "source": [
    "Try different parameters of LightGBM model to see how it affects the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "053a23cc-866e-4c94-bdee-25a2d9983b76",
    "cellId": "u5b53usaj27ppgdurar3mk"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "params = {'num_leaves': 512,\n",
    "           'learning_rate': 0.1,\n",
    "           'min_split_gain': 0.1,\n",
    "           'min_child_weight': 30,\n",
    "           'reg_lambda': 1,\n",
    "           'subsample': 1,\n",
    "           'objective':'binary',\n",
    "           'task': 'train',\n",
    "           'verbose': -1\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "6f13fc32-d870-4e12-8675-b3090e2920cb",
    "cellId": "nvqcpueulfp1d78wh008on",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "for train_index, test_index in tqdm(skf.split(features, labels)):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n",
    "    clf = lgb.train(params, lgb_train, num_boost_round=500, verbose_eval=False)\n",
    "    y_pred_proba = clf.predict(X_test, verbose_eval=False)\n",
    "    cm_dict = classification_metrics(y_test, y_pred_proba)\n",
    "    print(cm_dict)\n",
    "    cv_results = cv_results.append(classification_metrics(y_test, y_pred_proba),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "37ea3224-7a34-4992-a9b4-29e0e1aab56d",
    "cellId": "l7pkfkaxtsbfm74ve7jkip"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "lgb_train = lgb.Dataset(features, labels, free_raw_data=False)\n",
    "clf = lgb.train(params, lgb_train, num_boost_round=500)\n",
    "y_pred_proba = clf.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "f34486f6-6637-471a-a921-6f0457057e7d",
    "cellId": "ntctfzulh3zslbh75jgt"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "# Function for displaying the error matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"Plots a confusion matrix.\n",
    "    Source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    cm_max = cm.max()\n",
    "    cm_min = cm.min()\n",
    "    if cm_min > 0: cm_min = 0\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm_max = 1\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    thresh = cm_max / 2.\n",
    "    plt.clim(cm_min, cm_max)\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i,\n",
    "                 round(cm[i, j], 3),  # round to 3 decimals if they are float\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "7447e2c4-f146-4e9f-b283-92b01ffc3492",
    "cellId": "hjiaxecg16nogpaxsvef"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "cm = np.asarray(classification_metrics(labels, y_pred_proba)['Confusion Matrix'])\n",
    "plot_confusion_matrix(cm, ['fail','pass'], normalize=True)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "45758f4a-4989-4b81-bcaa-6b6f3f8dd7b3",
    "cellId": "g6hsza252wj9rens9vi1dm",
    "execution_id": "1e3647e4-5aad-41df-a243-68595b72adb9"
   },
   "source": [
    "## Saving the model\n",
    "\n",
    "Save the model to the project folder. You will download this file in the next notebook to visualize the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "4bd79378-ad56-493c-bb00-e6e89e76b84e",
    "cellId": "7o0pgsixpsggokcgk1mxu"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model_path = 'lightgbm_classifier.model'\n",
    "clf.save_model(model_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "ac6f4850-69e8-4fad-a6ff-4775b42ce3b2",
  "notebookPath": "ML/model-building.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
